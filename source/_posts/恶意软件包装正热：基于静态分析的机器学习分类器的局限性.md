---
title: 恶意软件包装正热：基于静态分析的机器学习分类器的局限性
categories:
  - 想要毕业
  - 密码学进展
description: 安全相关论文阅读讨论
abbrlink: 28034c81
date: 2021-04-24 14:31:28
tags:
cover:
katex:
---

# 论文阅读

论文相关信息：[When Malware is Packin’ Heat;Limits of Machine Learning Classifiers Based on Static Analysis Features](https://www.ndss-symposium.org/ndss-paper/when-malware-is-packin-heat-limits-of-machine-learning-classifiers-based-on-static-analysis-features/)

> *Abstract*—Machine learning techniques are widely used in addition to signatures and heuristics to increase the detection rate of anti-malware software, as they automate the creation of detection models, making it possible to handle an ever-increasing number of new malware samples. In order to foil the analysis of anti-malware systems and evade detection, malware uses packing and other forms of obfuscation. However, few realize that benign applications use packing and obfuscation as well, to protect intellectual property and prevent license abuse.
>
> In this paper, we study how machine learning based on static analysis features operates on packed samples. Malware researchers have often assumed that packing would prevent machine learning techniques from building effective classifiers. However, both industry and academia have published results that show that machine-learning-based classifiers can achieve good detection rates, leading many experts to think that classifiers are simply detecting the fact that a sample is packed, as packing is more prevalent in malicious samples. We show that, different from what is commonly assumed, packers do preserve some information when packing programs that is “useful” for malware classification. However, this information does not necessarily capture the sample’s behavior. We demonstrate that the signals extracted from packed executables are *not rich enough* for machine-learning-based models to generalize their knowledge to operate on unseen packers, and be robust against adversarial examples. We also show that a naive application of machine learning techniques results in a substantial number of false positives, which, in turn, might have resulted in incorrect labeling of ground-truth data used in past work.

摘要--机器学习技术被广泛用于签名和启发式方法，以提高反恶意软件的检测率，因为它们可以自动创建检测模型，使其有可能处理数量不断增加的新恶意软件样本。为了挫败反恶意软件系统的分析并逃避检测，恶意软件使用包装和其他形式的混淆。然而，很少有人意识到，良性应用程序也使用包装和混淆，以保护知识产权和防止许可证滥用。

在本文中，我们研究了基于静态分析特征的机器学习如何在打包样本上运行。恶意软件研究人员通常认为，包装会阻止机器学习技术建立有效的分类器。然而，工业界和学术界都发表了一些结果，表明基于机器学习的分类器可以实现良好的检测率，导致许多专家认为，分类器只是检测样本被包装的事实，因为包装在恶意样本中更普遍。`我们表明`，与通常的假设不同，打包器在打包程序时确实保留了一些对恶意软件分类 "有用 "的信息。然而，这些信息并不一定能捕捉到样本的行为。`我们证明`，从打包的可执行文件中提取的信号不够丰富，基于机器学习的模型无法将它们的知识普及到未见过的打包程序上，也无法对对抗性的例子保持稳定。`我们还表明`，机器学习技术的天真应用导致了大量的假阳性，这反过来又可能导致在过去的工作中对地面真实数据的错误标记。

## I. INTRODUCTION

> Anti-malware software provides end-users with a means to detect and remediate the presence of malware on their machines. Most anti-malware software traditionally consists of two parts: a signature-based detector and a heuristics- based classifier. While signature-based methods detect similar versions of known malware families with a small error rate, they become insufficient as an ever-increasing number of new malware samples are being identified. VirusTotal reports that, on average, over 680,000 new samples are analyzed per day, of which some are merely repacked versions of previously seen samples with identical behavior. Over the last few years, the need for techniques that generalize to new, unknown malware samples while removing expensive human experts from the loop has led to approaches that leverage both static and dynamic analyses combined with data mining and machine learning techniques.

反恶意软件为终端用户提供了检测和补救其机器上的恶意软件的手段。大多数反恶意软件传统上由两部分组成：一个基于签名的检测器和一个基于启发式的分类器。虽然基于签名的方法能以较小的错误率检测到已知恶意软件家族的类似版本，但随着越来越多的新恶意软件样本被发现，这些方法变得不够用。VirusTotal报告说，平均每天有超过68万个新样本被分析，其中一些只是以前看到的样本的重新包装版本，具有相同的行为。在过去的几年里，由于需要能够概括新的、未知的恶意软件样本的技术，同时将昂贵的人类专家从循环中移除，导致了利用静态和动态分析与数据挖掘和机器学习技术相结合的方法。

> Although dynamic analysis provides a clear picture of an executable’s behavior, it has some issues in practice: for example, dynamic analysis of untrusted code requires either kernel-level privileges, thus expanding the attack surface, or a virtual machine, which requires a substantial amount of computing resources. In addition, malware usually employs environmental checks to avoid detection, and the virtualized environment may not reflect the environment targeted by the malware. To avoid such limitations, some approaches heavily rely on features ex- tracted through static analysis. These approaches are appealing to anti-malware companies that want to replace anti-malware systems based on dynamic analysis. These static-analysis- based anti-malware vendors, which have quickly grown into billion-dollar companies, boast that their tools leverage “AI techniques” to determine the maliciousness of programs solely based on their static features (i.e., without having to execute them). However, static analysis has known issues when applied to obfuscated and packed samples.

虽然动态分析提供了一个可执行文件行为的清晰图像，但它在实践中也有一些问题：例如，动态分析不受信任的代码需要内核级权限，从而扩大攻击面，或者需要一个虚拟机，这需要大量的计算资源。此外，恶意软件通常采用环境检查来避免检测，而虚拟化环境可能无法反映恶意软件的目标环境。为了避免这种限制，一些方法严重依赖通过静态分析得出的特征。这些方法对那些想取代基于动态分析的反恶意软件系统的反恶意软件公司很有吸引力。这些基于静态分析的反恶意软件供应商已经迅速成长为价值数十亿美元的公司，他们吹嘘自己的工具利用 "人工智能技术"，仅根据程序的静态特征（即，无需执行它们）来确定其恶意程度。然而，静态分析在应用于混淆和包装的样本时有已知的问题。

> It is commonly assumed that packing greatly hinders machine learning techniques that leverage features extracted from static (file) analysis. However, both industry and academia have published results showing that machine-learning-based classifiers can achieve good detection rates. Many experts assume that these results are due to the fact that classifiers just learn to distinguish between packed and unpacked programs. In fact, we would expect that machine-learning-based classifiers will deliver poor performance in real-world settings, where packing is increasingly seen in both malicious and benign software. Unfortunately, most related work did not consider or only briefly discussed the effects of packing when proposing machine-learning-based classifiers. Surprisingly, our initial experiments showed that machine-learning-based classifiers can distinguish between packed benign and packed malicious samples in our dataset. This led us to the following research question: does static analysis on *packed* binaries provide a *rich enough* set of features to build a malware classifier using machine learning?

人们通常认为，包装大大阻碍了利用从静态（文件）分析中提取的特征的机器学习技术。然而，工业界和学术界都发表了一些结果，表明基于机器学习的分类器可以达到良好的检测率。许多专家认为，这些结果是由于分类器只是学习区分打包和未打包的程序。事实上，我们预计基于机器学习的分类器在现实世界中的表现会很差，因为在现实世界中，恶意软件和良性软件都越来越多地出现打包现象。不幸的是，在提出基于机器学习的分类器时，大多数相关工作都没有考虑或只是简单地讨论了打包的影响。令人惊讶的是，我们最初的实验表明，基于机器学习的分类器可以在我们的数据集中区分出打包的良性软件和打包的恶意软件样本。这促使我们提出了以下`研究问题：对包装好的二进制文件进行静态分析，是否能提供足够丰富的特征集，以利用机器学习建立一个恶意软件分类器`？

> Our experiments require a ground-truth dataset for which we can determine if each sample is packed or unpacked and malicious or benign. We created our first dataset, the *wild dataset*, with executables provided by a commercial anti-malware vendor, which uses dynamic features, combined with the labeled benchmark dataset EMBER. We leveraged the vendor’s sandbox, along with VirusTotal, to remove samples with inconsistent benign/malicious labels from the dataset. For identifying packed executables, we used the vendor’s sandbox combined with the Deep Packer Inspector tool and a number of static tools. The fact that we built the dataset mainly based on the runtime behavior of samples gives us high confidence in our ground truth labels. We created a second dataset, the *lab dataset*, by packing all the executables in the *wild dataset* with widely used commercial and free packers. Following a detailed literature study, we extracted nine families of features from the executables in the two datasets. Even though in our experiments we used SVM, deep neural networks (i.e., MalConv), and different variants of decision-tree learners, like random forest, we only discuss the results of the random forest approach as we observed similar findings for these approaches, with random forest being the best classifier in most experiments, and random forest allows for better interpretation of the results compared to neural networks.

我们的实验需要一个真实的数据集：我们可以确定每个样本是打包的还是未打包的，是恶意的还是良性的。我们用一个商业反恶意软件供应商提供的可执行文件创建了我们的第一个数据集--`野生数据集`，该数据集使用动态特征，并与标记的基准数据集EMBER相结合。我们利用供应商的沙盒和VirusTotal，从数据集中去除良性/恶性标签不一致的样本。为了识别打包的可执行文件，我们使用了供应商的沙盒与Deep Packer Inspector工具和一些静态工具。我们主要根据样本的运行时行为来建立数据集，这让我们对我们的基础事实标签有很高的信心。我们通过广泛使用的商业和免费打包器打包野生数据集中的所有可执行文件创建了第二个数据集--`实验室数据集`。经过详细的文献研究，我们从这两个数据集中的可执行文件中提取了九个系列的特征。尽管在实验中我们使用了SVM、深度神经网络（即MalConv）和决策树学习器的不同变体，如随机森林，但我们只讨论随机森林方法的结果，因为我们观察到这些方法有类似的发现，随机森林是大多数实验中的最佳分类器，而且与神经网络相比，随机森林可以更好地解释结果。

> As a naive experiment, we first trained the classifier on *packed malicious* and *unpacked benign* samples. The resulting classifier produced a high false positive rate on *packed benign* samples, which shows that the classifier is biased towards detecting *packing*. Using n-grams, Perdisci et al. also observed that *packing detection* is an easier task to learn compared to detecting maliciousness. In addition, we demon- strated that “packer classification” is a trivial task by training a packer classifier using samples from each packer (class) in the *lab dataset*. The classifier achieved precision and recall greater than 99.99% for each class. This indicates that a bias in the training set regarding packers may cause the classifier to learn specific packing routines as a sign of maliciousness. We verified this by training the classifier on benign and malicious executables packed by two non-overlapping subsets of packers, which we refer to as *good* and *bad* packers, respectively. The resulting classifier learned to label anything packed by *good* packers as benign, and anything packed by *bad* packers as malicious, regardless of whether or not the sample is malicious.

作为一个navie实验，我们首先在打包的恶意样本和未打包的良性样本上训练分类器。结果分类器在包装好的良性样本上产生了很高的假阳性率，这表明分类器偏向于检测包装。通过使用n-grams，Perdisci等人还观察到，与检测恶意相比，包装检测是一项更容易学习的任务。此外，我们通过使用实验室数据集中每个打包器（类）的样本训练打包器分类器，证明了 "打包器分类 "是一项琐碎的任务。该分类器对每个类别都达到了大于99.99%的精度和召回率。这表明，关于包装商的训练集的偏见可能导致分类器学习特定的包装程序作为恶意的标志。我们通过对由两个不重叠的打包器打包的良性和恶意的可执行文件进行分类器训练来验证这一点，我们把它们分别称为好的和坏的打包器。由此产生的分类器学会了将由好的打包器打包的任何东西标记为良性的，而将由坏的打包器打包的任何东西标记为恶意的，不管这个样本是否是恶意的。

> We extended the naive experiment by training the classifier on different training sets with increasing ratios of *packed benign* samples. To avoid the bias introduced by the use of *good* and *bad* packers, we selected packed samples from the *lab dataset* uniformly distributed over packers. Surprisingly, despite the popular assumption that packing hinders machine- learning-based classifiers, we found that increasing the packed benign ratio in the training set helped the classifier to maintain relatively low false positive and false negative rates. This shows that packers preserve some information about the original binary that can be leveraged for malware detection. For example, most packers keep .CAB file headers in the resource sections of the executables. Jacob et al. found a similar trend for packers that employ weak encryption or compression. By training on one packer at a time, we observed that the information preserved about the original binaries is not necessarily associated with malicious behavior, but is “useful” for malware detection. Nevertheless, we argue that such a classifier still suffers from three issues: inability to generalize, failure in the presence of strong encryption, and vulnerability to adversarial samples.

我们通过在不同的训练集上训练分类器来扩展naive实验，其中包装良性样本的比例不断增加。为了避免使用好的和坏的包装器所带来的偏差，我们从实验室数据集中选择了包装器均匀分布的包装样本。令人惊讶的是，尽管流行的假设是包装阻碍了基于机器学习的分类器，但我们发现，在训练集中增加包装的良性比率有助于分类器保持相对较低的假阳性和假阴性率。这表明，打包器保留了一些关于原始二进制文件的信息，可以用来进行恶意软件检测。例如，大多数打包器在可执行文件的资源部分保留了.CAB文件头。Jacob等人发现，采用弱加密或压缩的打包器也有类似的趋势。通过一次对一个打包器的训练，我们观察到，保留的关于原始二进制文件的信息不一定与恶意行为相关，但对恶意软件检测是 "有用的"。然而，我们认为这样的分类器仍然存在三个问题：无法归纳，在强加密的情况下失败，以及容易受到对抗性样本的影响。

> **Generalization**. Training the classifier on packed samples is not guaranteed to generalize to packers that are not included in the training set. We excluded one packer at a time from the training dataset and evaluated the classifier against samples packed with the excluded packer. We observed false positive rates of 43.65%, 47.49%, and 83.06% when excluding tElock, PECompact, and kkrunchy, respectively. Moreover, the classifier trained on *all* packers from the *lab dataset* produced a *false negative* rate of 41.98% on packed executables from the *wild dataset*. This means that although packers preserve some information, the trained classifier fails to generalize to previously unseen packing routines. This is a severe problem as malware authors often prefer customized packing routines to off-the-shelf packers.

**普及性**。在包装好的样品上训练分类器，并不能保证能推广到不包括在训练集中的包装商。我们每次从训练数据集中排除一个包装器，并针对被排除的包装器所包装的样品评估分类器。当排除tElock、PECompact和kkrunchy时，我们观察到假阳性率分别为43.65%、47.49%和83.06%。此外，在实验室数据集的所有打包器上训练的分类器对野生数r据集的打包可执行文件产生了41.98%的假阴性率。这意味着，虽然打包器保留了一些信息，但训练有素的分类器无法归纳以前未见过的打包程序。这是一个严重的问题，因为恶意软件作者往往喜欢定制的打包程序而不是现成的打包程序。

> **Strong & complete encryption**. We argue that an executable might be packed in a way that reveals no information related to its behavior until it is executed. As a preliminary step, we packed all executables in the *wild dataset* with our own packer, called *AES-Encrypter*, which encrypts the executable with AES and injects it as the overlay of the packed binary. When the packed program is executed, *AES-Encrypter* decrypts the over- lay and executes the original program within a new process. All static features are always the same, except for features extracted from the encrypted overlay. We trained and tested the classifier on executables packed by the *AES-Encrypter*, and, as expected, the classifier could not distinguish between benign and malicious executables packed by *AES-Encrypter*. This shows that packing can be performed without transferring any (static) initial pattern to the packed program, if properly optimized for this purpose.

**强而完整的加密**。我们认为，一个可执行文件在被执行之前，可能会以一种不透露其行为相关信息的方式被打包。作为初步步骤，我们用自己的打包器打包了野外数据集中的所有可执行文件，称为AES-加密器，它用AES对可执行文件进行加密，并将其作为打包后的二进制文件的覆盖层注入。当打包后的程序被执行时，AES-Encrypter会解密覆盖层，并在一个新的进程中执行原始程序。除了从加密的覆盖层中提取的特征外，所有的静态特征都是一样的。我们在由AES-加密器打包的可执行文件上训练和测试了分类器，正如预期的那样，分类器无法区分由AES-加密器打包的良性和恶意可执行文件。这表明，如果为此目的进行了适当的优化，可以在不将任何（静态）初始模式转移到打包程序的情况下进行打包。

> **Adversarial samples**. Machine-learning-based malware classi- fiers have been shown to be vulnerable against adversarial sam- ples, especially those that use only static analysis features. We expect that generating such adversarial samples would be easier in our case, as static analysis of packed binaries does not provide features that capture a sample’s behavior. We first trained the classifier on a dataset whose benign and malicious samples are packed with the same pack- ers so that the classifier is not biased to detect specific packing routines as a sign of maliciousness. The classifier maintained a low error rate. From all malicious samples that the classifier detected successfully, we managed to generate new samples that the classifier no longer detects as malicious. Specifically, we identified “benign” sequences of bytes that occurred more frequently in benign samples and injected them into the target binary without affecting the sample’s behavior. Very recently, a group of researchers used a very similar technique to trick Cylance’s AI-based anti-malware engine into thinking that malware like WannaCry and tools such as Mimikatz were benign. They did this by taking strings from an online gaming program and injecting them into malicious files. Since games are highly obfuscated and packed, they confront such an engine with a dilemma; either inherit a bias towards games or produce high rates of false positives for them.

**对抗性样本**。基于机器学习的恶意软件分类器已被证明容易受到对抗性样本的影响，特别是那些只使用静态分析特征的样本。我们预计，在我们的案例中，产生这样的对抗性样本会更容易，因为对打包的二进制文件的静态分析并不能提供捕捉样本行为的特征。我们首先在一个数据集上训练分类器，这个数据集的良性样本和恶意样本是用相同的打包器打包的，这样分类器就不会偏向于检测特定的打包程序作为恶意行为的标志。该分类器保持了较低的错误率。从分类器成功检测到的所有恶意样本中，我们设法生成了分类器不再检测为恶意的新样本。具体来说，我们确定了在良性样本中出现频率较高的 "良性 "字节序列，并将其注入目标二进制文件中，而不影响样本的行为。最近，一组研究人员使用了一种非常类似的技术来欺骗Cylance的基于人工智能的反恶意软件引擎，使其认为像WannaCry这样的恶意软件和Mimikatz这样的工具是良性的。他们通过从一个在线游戏程序中提取字符串，并将其注入恶意文件中做到了。由于游戏是高度混淆和包装的，它们让这样的引擎面临两难境地；要么继承对游戏的偏见，要么对游戏产生高比率的误报。

> To investigate how real-world malware detectors operate on packed executables, we submitted benign and malicious exe- cutables packed by each packer to VirusTotal. We only focused on six machine-learning-based engines that use only static analysis features according to their description on VirusTotal or the company’s website. Unfortunately, we observed that all these six engines learned that packing implies maliciousness. It must be noted that, we used commercial packers, like Themida, PECompact, PELock, and Obsidium, that legitimate software companies use to protect their software. Nevertheless, benign programs packed by these packers were detected as malware.

为了研究现实世界中的恶意软件检测器是如何对打包的可执行文件进行操作的，我们向VirusTotal提交了由每个打包器打包的良性和恶意的可执行文件。我们只关注六个基于机器学习的引擎，根据它们在VirusTotal或公司网站上的描述，它们只使用静态分析功能。不幸的是，我们观察到，这六个引擎都认为打包意味着恶意。必须指出的是，我们使用了商业打包器，如Themida、PECompact、PELock和Obsidium，这些都是合法软件公司用来保护其软件的。然而，由这些打包器打包的良性程序被检测为恶意软件。

> As packing is being increasingly adopted by legitimate software, the anti-malware industry needs to do better than detecting packers, otherwise good and bad programs are misclassified, causing pain to users and eventually resulting in alert fatigue and missed detections. This is especially a concern for previous studies that rely on anti-malware products for establishing ground truth, as misclassification of packed benign programs might have biased those studies.

由于打包被越来越多的合法软件所采用，反恶意软件行业需要做得比仅检测打包器更好，否则好的和坏的程序会被错误分类，给用户带来痛苦，最终导致警报疲劳和漏检。这对于以前依靠反恶意软件产品建立基础真相的研究来说尤其令人担忧，因为对打包的良性程序的错误分类可能会使这些研究产生偏差。

> In summary, we make the following contributions:
>
> - We study the limits of machine-learning-based malware classifiers that use only static features. We show that the lack of overlap between packers used in benign and malicious samples causes the classifier to associate specific packers with maliciousness. We show that, if trained correctly, the classifier is able to distinguish between benign and malicious samples packed by real-world packers, though it remains susceptible to unseen packing routines or, even worse, to the application of strong encryption to the entire program. Furthermore, we show that it is possible to craft evasive samples that bypass detecition via a naive adversarial attack.
> - Our evaluation of six products on VirusTotal shows that current *static* machine-learning-based anti-malware engines detect packing instead of maliciousness.
> - We release a dataset of 392,168 executables for which we know whether each sample is benign or malicious, and packed or unpacked. We also know the specific packer for the *lab dataset*, which includes 341,444 executables.
>
> We release the source code of all experiments in a Docker image at https://github.com/ucsb-seclab/packware to support the reproducibility of our results.

综上所述，我们做出了以下`贡献`。

- 我们研究了仅使用静态特征的基于机器学习的恶意软件分类器的局限性。我们表明，良性和恶意样本使用的打包器之间缺乏重叠，导致分类器将特定的打包器与恶意联系起来。我们表明，如果训练得当，分类器能够区分由现实世界的打包器打包的良性和恶意样本，尽管它仍然容易受到看不见的打包程序的影响，或者更糟糕的是，对整个程序应用强加密的影响。此外，我们还表明，通过简单的对抗性攻击，有可能制作出绕过检测的规避样本。
- 我们对VirusTotal上的六种产品的评估表明，目前基于静态机器学习的反恶意软件引擎检测的是包装而不是恶意。
- 我们发布了一个包含392,168个可执行文件的数据集，我们知道每个样本是良性的还是恶意的，是打包的还是解包的。我们还知道实验室数据集的具体打包者，其中包括341,444个可执行文件。

## II. MOTIVATION

> Packing has long been an effective method for malware authors to evade the signature-based detection of anti-malware engines, but little is known about its legitimate usage in benign applications. As the first step in this direction, in 2013, Lakshman Nataraj explored how anti-malware scanners available on VirusTotal handle packing. He packed 16,663 benign system executables from various Windows OS versions with four different packers (UPX, Upack, NSPack, and BEP), and submitted them to VirusTotal. He showed that 96.7% of the files packed with Upack, NSPack, and BEP triggered at least ten detections on VirusTotal. Another recent study mined byte pattern-based signatures of anti- malware products to force misclassifications of benign files, and also found that the artifacts of packers are effective as “malicious markers.” We argue that these results stem from the fact that packing historically has been associated with malware only. Consequently, a na ̈ıve detection approach only based on static features from packed samples will be heavily biased towards associating packing with malicious behavior. In fact, static analysis features that are shown to be useful for packing detection are also being used by machine-learning-based malware detectors.

长期以来，包装一直是恶意软件作者躲避反恶意软件引擎基于签名的检测的有效方法，但人们对其在良性应用中的合法使用却知之甚少。作为这个方向的第一次尝试，2013年，Lakshman Nataraj探索了VirusTotal上的反恶意软件扫描器如何处理打包。他用四种不同的打包器（UPX、Upack、NSPack和BEP）打包了来自不同Windows操作系统版本的16663个良性系统可执行文件，并将它们提交给VirusTotal。他表明，96.7%的用Upack、NSPack和BEP打包的文件在VirusTotal上引发了至少10次检测。另一项最近的研究挖掘了基于字节模式的反恶意软件产品的签名，以强制对良性文件进行错误分类，并且还发现打包器的工件作为 "恶意标记 "是有效的。我们认为，这些结果源于一个事实，即包装在历史上只与恶意软件有关。因此，仅基于打包样本的静态特征的naive检测方法将严重偏向于将打包与恶意行为联系起来。事实上，被证明对包装检测有用的静态分析也正被基于机器学习的恶意软件检测器使用。

> We collected a large-scale, real-world dataset of malicious, suspicious, and benign files from a commercial vendor of advanced malware protection products. This dataset includes samples that the vendor analyzed from customers around the globe over the past three years. As Figure 1 shows, packing is not only widespread in malware samples (75%), but also common in benign samples (50% in the worst case). Note that Figure 1 presents a lower bound for the ratio of packed executables. Our findings overlap with the findings of Rahbarinia et al. , who studied 3 million web-based software downloads over 7 months in 2014, finding that *both* malicious and benign files use known packers (58% and 54%, respectively). Making matters even worse, more than half of the 69 unique packers they observed (e.g., INNO, UPX) are being used by both malicious and benign software. While some packers (e.g., NSPack, Molebox) were exclusively used to pack malware in their dataset, they conclude that packing information alone is not a good indicator of malicious behavior. We further packed 613 executables from a fresh installation of Windows 10 (located in *C:*\Windows\System32) with Themida and submitted them to VirusTotal. Figure 2 shows the his- togram of the number of detections. Unsurprisingly, out of 613 binaries, 564 binaries were detected as malicious by more than 10 anti-malware tools. If we consider only the six machine- learning-based anti-malware engines on VirusTotal, out of 613 binaries, 553 binaries were detected as malicious by more than four tools.

我们从一家高级恶意软件保护产品的商业供应商那里收集了一个大规模的、真实世界的恶意、可疑和良性文件的数据集。该数据集包括该供应商在过去三年中从全球客户那里分析的样本。如图1所示，包装不仅在恶意软件样本中普遍存在（75%），而且在良性样本中也很常见（最差情况下为50%）。请注意，`图1`显示的是打包可执行文件的比例的下限。我们的发现与Rahbarinia等人的研究结果重叠，他们在2014年7个月内研究了300万次基于网络的软件下载，发现恶意和良性文件都使用已知的打包器（分别为58%和54%）。更糟糕的是，在他们观察到的69个独特的打包器中，有一半以上（例如INNO、UPX）被恶意软件和良性软件使用。虽然有些打包器（如NSPack、Molebox）在他们的数据集中专门用于打包恶意软件，但他们的结论是，仅仅打包信息并不是恶意行为的良好指标。我们用Themida进一步打包了613个来自新安装的Windows 10的可执行文件（位于C:\Windows\System32），并将它们提交给VirusTotal。`图2`显示了检测到的数量的图表。不出所料，在613个二进制文件中，有564个二进制文件被10个以上的反恶意软件工具检测为恶意的。如果我们只考虑VirusTotal上的六个基于机器学习的反恶意软件引擎，在613个二进制文件中，有553个二进制文件被四个以上的工具检测为恶意。

![image-20210424171432980](/Users/foo/Desktop/tmpimg/image-20210424171432980.png)

> As these numbers show, any approach that fails to consider packed benign samples when designing and evaluating a malware detection approach ultimately results in a substantial number of false positives on real-world data. This is especially a concern for machine-learning-based approaches, which, in the absence of reliable and fresh ground truth, frequently rely on labels from anti-malware products available on VirusTotal. Given the disagreement of anti-malware products in labeling samples, a common practice is to sanitize a dataset, for example, by considering decisions from a selected set of anti-malware products, or, as another example, by using a voting-based consensus. While this approach is problematic for various reasons, we believe that one main aspect is particularly troublesome: *Dataset pollution*. Packed benign samples that are detected by anti-malware products as malicious are incorrectly used as malware samples. For example, a recent related work used a similar procedure for labeling, as stated by the authors: “We train a classifier using supervised learning and therefore require a target label for each sample (0 for benign and 1 for malware). We use malware indicators from VirusTotal. For each sample, we count the number of malicious detections from the various engines aggregated by VirusTotal, weighted according to a reputation we give to each engine, such that several well-known engines are given weight >1, and all others are weighted 1. We use the result to label a sample benign or malicious.” While we do not know which weights are used by the authors, there is a good chance that their dataset is skewed, since, as we showed above, a number of anti-malware engines on VirusTotal detect packed benign samples as malware.

正如这些数字所显示的那样，任何在设计和评估恶意软件检测方法时未能考虑打包的良性样本的方法，最终都会在真实世界的数据中产生大量的误报。这对于基于机器学习的方法来说尤其令人担忧，因为在缺乏可靠和新鲜的基础真相的情况下，这些方法经常依赖VirusTotal上的反恶意软件产品的标签。鉴于反恶意软件产品在标记样本方面的分歧，一种常见的做法是对数据集进行消毒，例如，考虑来自选定的反恶意软件产品的决定，或者，作为另一个例子，使用基于投票的共识。虽然这种方法由于各种原因存在问题，但我们认为有一个主要方面是特别麻烦的：数据集污染，即被反恶意软件产品检测为恶意的打包良性样本被错误地作为恶意软件样本使用。例如，最近的一项相关工作使用了类似的程序进行标记，正如作者所说。"我们使用监督学习来训练分类器，因此需要给每个样本一个目标标签（0代表良性，1代表恶意软件）。我们使用VirusTotal的恶意软件指标。对于每个样本，我们计算由VirusTotal汇总的各种引擎的恶意检测数量，根据我们给每个引擎的声誉进行加权，例如几个著名的引擎的权重大于1，而所有其他引擎的权重为1。虽然我们不知道作者使用了哪些权重，但他们的数据集很有可能是有偏差的，因为正如我们上面所显示的，VirusTotal上的一些反恶意软件引擎将打包的良性样本检测为恶意软件。

> As studied by the anti-malware community, evaluating existing malware detection methodologies poses substantial challenges. For example, Rossow et al. presented guidelines for collecting and using malware datasets. Our work aims to find whether packing even retains *rich enough* static features from the original binary to detect anything meaningful besides the packing itself. To the best of our knowledge, no prior work has considered the effects of packed executables on machine-learning-based malware detectors that leverage only static analysis features.

正如反恶意软件界所研究的那样，评估现有的恶意软件检测方法带来了巨大的挑战。例如，Rossow等人提出了收集和使用恶意软件数据集的指导方针。我们的工作旨在寻找包装是否从原始二进制文件中保留了足够丰富的静态特征，以检测除了包装本身之外的任何有意义的东西。据我们所知，以前的工作没有考虑过打包的可执行文件对只利用了静态分析特征的基于机器学习的恶意软件检测器的影响。

## III. BACKGROUND

### *A. Executable Packers*

> A packer is a software component that applies a set of routines to compress or encrypt a target program. The simplest form of packing consists of the decryption or decompression (at runtime) of the original payload followed by a jump to the memory address that contains the target payload (this technique is called “tail jump”). Ugarte et al. classify packers into six types, with an increasing level of complexity in the reconstruction of the target payload:
>
> Type I: A single unpacking routine is executed to transfer the control to the original program. UPX is the most popular packer in this class. Type II: The packer employs a chain of unpacking routines executed sequentially, with the original code recomposed at the end of the chain. Type III: Unpacking routines include loops and backward edges. Though the origi- nal code is not necessarily reconstructed in the last layer, a tail transition still exists to separate the packer and the application code. Type IV: In each layer of packing, the corresponding part of the unpacking routine is interleaved with the corresponding part of the original code. However, the entire original code will be completely unpacked in memory at some point during the execution. Type V: The packer is composed of different layers in which the unpacking code is mangled with the original code. There are multiple tail jumps that reveal only a single frame of the original code at a time. Type VI: Packers reveal (unpack) only a single fragment of the original code (as little as a single instruction) at any given time.

打包器是一个软件组件，它应用一套程序来压缩或加密目标程序。最简单的打包形式包括对原始有效载荷进行解密或解压缩（在运行时），然后跳转到包含目标有效载荷的内存地址（这种技术被称为 "尾跳"）。Ugarte等人将打包器分为六种类型，在重建目标有效载荷方面的复杂程度越来越高：

Type I：执行单一的解包程序，将控制权转移到原始程序。UPX是这一类中最流行的打包器。

Type II：打包器采用一连串的解包例程，依次执行，原代码在链的末端重新组成。

Type III：解包程序包括循环和后向边缘。尽管原始代码不一定在最后一层被重构，但仍然存在一个尾部过渡，将打包程序和应用程序代码分开。

Type IV：在每一层打包中，解包程序的相应部分与原代码的相应部分交错在一起。然而，整个原代码将在执行过程中的某个时刻在内存中被完全解包。

Type V：打包程序由不同的层组成，其中解包代码与原代码混杂在一起。有多个尾部跳转，每次只显示原代码的一个框架。

Type VI：打包者在任何时候都只揭示（解包）原代码的一个片段（少到一个指令）。

> We discuss approaches that are proposed for packing detection, packer identification, and automated unpacking in Appendix A. Here, we discuss the limitations of these methods.

我们在附录A中讨论了为包装检测、包装器识别和自动解包提出的方法。在这里，我们讨论这些方法的局限性。

#### Limitations of packing detection

> Signature-based ap- proaches to packing detection have a high false negative rate, as they require a priori knowledge of packed executables generated by each packer. As an example, PEiD is shown to have approximately a 30% false negative rate. Other approaches apply static analysis to extract a set of features or use hand-crafted heuristics to detect packed executables. However, they are vulnerable to adversaries. As an example, the Zeus malware family applies different techniques, such as inserting a selected set of bytes into executables, in order to keep the entropy of the file and its sections low. Such malware evades entropy-based heuristics, as they are often used to determine if an executable is packed. Dynamic approaches seem to perform better, since they often look for a write-execute sequence in a memory location, which is the definition of packing. However, packed executables usually employ different techniques to evade analysis, like conditional execution of unpacking routines.

**包装检测的局限性**。基于签名的打包检测方法有很高的假阴性率，因为它们需要对每个打包者产生的打包可执行文件有先验的了解。比如PEiD被证明有大约30%的假阴性率。其他方法应用静态分析来提取一组特征或使用手工制作的启发式方法来检测打包的可执行文件。然而，它们很容易受到对手的攻击。举个例子，Zeus恶意软件家族应用了不同的技术，如在可执行文件中插入一组选定的字节，以保持文件及其部分的熵值较低。这种恶意软件逃避了基于熵的启发式方法，因为它们通常被用来确定一个可执行文件是否被打包。动态方法似乎表现得更好，因为它们经常在内存位置寻找一个写-执行序列，这是打包的定义。然而，打包的可执行文件通常采用不同的技术来逃避分析，如有条件地执行解包程序。

#### Limitations of generic unpackers

> Packers usually employ different techniques to evade analysis approaches utilized by generic unpackers. For example, tELock and Armadillo lever- age several anti-debugging routines to terminate the execution in a debugging setting. Although some unpackers ex- ploit hardware virtualization to achieve transparency, the introduced performance overhead could be unacceptable. Themida applies virtualization obfuscation to its unpacking routine, which can cause slice size explosion. In general, generic unpackers rely on a number of assumptions that do not necessarily hold in practice: the entire original code is in memory at a certain point, the original code is unpacked in the last layer, the execution of the unpacking routine and the original code are completely separated, and the unpacking code and the original code run in the same process without any inter-process communication. These simplifications make these unpackers inadequate for handling the challenges introduced by complex, real-world packers. Moreover, generic unpackers often rely on heuristics that are designed for specific packers.

**通用解包器的局限性**。打包器通常采用不同的技术来规避通用解包器所使用的分析方法。例如，tELock和Armadillo利用几个反调试程序来终止调试环境下的执行。尽管一些解包程序利用硬件虚拟化来实现透明性，但引入的性能开销可能是不可接受的。Themida在其解包程序中应用了虚拟化混淆，这可能会导致片断大小爆炸。一般来说，通用的解包程序依赖于一些假设，这些假设在实践中不一定成立：整个原始代码在某一点上都在内存中，原始代码在最后一层被解包，解包例程和原始代码的执行完全分开，解包代码和原始代码在同一个进程中运行，没有任何进程间的通信。这些简化使得这些解包器不足以处理复杂的、真实世界的打包器所带来的挑战。此外，通用的解包器往往依赖于为特定的打包器设计的启发式方法。

### *B. Packing vs. Static Malware Analysis*

> In Appendix B, we discuss how machine learning is being adopted by the anti-malware community to statically analyze malicious programs. In particular, we reviewed a wide range of static malware analysis approaches based on machine learning. Although static malware detectors have been shown to be biased towards detecting packing, we observed a number of limitations in related work when it comes to the handling of packed executables. In particular, out of the 30 papers mentioned above: (1) Ten papers do not mention packing or obfuscation techniques. (2) Ten approaches work only on unpacked executables, as mentioned by the authors. They used either unpacked executables or executables that they managed to unpack. (3) Seven papers claim to perform well in malware classification regardless of whether or not the executables are packed. However, the authors did not discuss whether any bias in terms of packing was present in their dataset or not. More precisely, they did not mention using packed benign executables in their dataset, or brief examinations have been done on the effects of packed executables, though the evaluation has been thoroughly carried out only on unpacked executables. (4) Only three papers focused on packed executables. However, they have two major limitations: (a) they use signature-based packer detectors, such as PEiD, to detect packing, while PEiD has approximately a 30% false negative rate, and (b) they augmented their datasets by packing benign executables using only a small number of packers. However, malicious executables might be packed with a different set of packers, which can result in a bias towards detecting specific packing techniques. Jacob et al. detect similar malware samples even if they are packed, yet, their method is resilient only against packers that employ compression or weak encryption, as they acknowledge.

在附录B中，我们讨论了机器学习是如何被反恶意软件社区采用来静态分析恶意程序的。特别地，我们审查了广泛的基于机器学习的静态恶意软件分析方法。虽然静态恶意软件检测器已被证明偏向于检测打包，但我们观察到相关工作在处理打包的可执行文件时存在一些局限性。在上述30篇论文中：(1) 10篇论文没有提到打包或混淆技术。(2) 10篇方法只在未打包的可执行文件上工作。他们要么使用未打包的可执行文件，要么使用他们设法解压的可执行文件。(3) 七篇论文声称，无论可执行文件是否被打包，恶意软件分类器都表现良好。然而，作者并没有讨论他们的数据集中是否存在包装方面的偏差。更确切地说，他们没有提到在他们的数据集中使用打包的良性可执行文件，或者对打包的可执行文件的影响做了简单的检查，评估只在未打包的可执行文件上彻底进行了。(4) 只有三篇论文专注于打包的可执行文件。然而，它们有两个主要的局限性。(a) 他们使用基于签名的打包器检测器，如PEiD，来检测打包，而PEiD有大约30%的假阴性率，(b) 他们通过只使用少量的打包器打包良性可执行文件来增强他们的数据集。然而，恶意可执行文件可能是用不同的打包器打包的，这可能导致对检测特定打包技术的偏见。Jacob等人检测到类似的恶意软件样本，即使它们被打包。然而，他们的方法只对采用压缩或弱加密的打包器有效，正如他们承认的那样。

> Finally, most related work did not publish their datasets, hence these approaches cannot be fairly compared to each other.

最后，大多数相关的工作没有公布他们的数据集，因此这些方法不能被公平地相互比较。

## IV. DATASET

> Our experiments require a dataset composed of executable programs for which we know if they are: (1) benign or malicious and (2) packed or unpacked. We combined a labeled dataset from a commercial vendor with the EMBER dataset (labeled) to build our *wild dataset*. We leveraged a hybrid approach to label an executable as packed or unpacked. We built another ground-truth dataset, the *lab dataset*, by packing all executables in the *wild dataset* with widely used com- mercial and free packers and our own packer, *AES-Encrypter*. Following a detailed study of the literature, we extracted nine families of features for all samples.

我们的实验需要一个由可执行程序组成的数据集，我们需要知道这些程序是：(1)良性或恶意的，(2)打包或未打包的。我们将一个来自商业供应商的标记数据集与EMBER数据集（标记）结合起来，建立我们的野生数据集。我们利用一种混合方法将一个可执行文件标记为已打包或未打包。我们用广泛地使用商业和免费打包器以及我们自己的打包器AES-Encrypter打包野生数据集中的所有可执行文件，从而建立了另一个基础真实数据集，即实验室数据集。经过对文献的详细研究，我们为所有的样本提取了九个系列的特征。

### *A. Wild Dataset*

> We used two different sources to create our *wild dataset* of Windows x86 executables. (1) A commercial anti-malware vendor provided 29,573 executables. These samples, observed “in the wild,” were randomly selected from an original pool that was analyzed by the anti-malware vendor’s sandbox in the US during the period from 2017-05-15 to 2017-09-19. Along with the benign/malicious label and the malicious behaviors observed during the execution, the vendor identified which executable was packed or not. (2) A labeled benchmark dataset, called EMBER, was introduced by Anderson et al. for training machine learning models to statically detect Windows mal- ware. This dataset consists of 800,000 Windows executables that are labeled. However, no information is provided regarding packing. We randomly selected 56,411 x86 executables from this dataset and submitted each sample to the commercial anti-malware vendor’s sandbox, in order to identify if the sample is packed. This also provides us confirmation whether an executable is malware or benign software, as the sandbox detects malicious behavior. Note that samples from these two sources were observed “in the wild” sometime in 2017, allowing more than enough time for current anti-malware engines to have incorporated means to detect them. As these two sources might have samples that are incorrectly labeled,we performed a careful and extensive post-processing step, which we describe in the following paragraphs.

我们使用两个不同的来源来创建我们的Windows x86可执行文件的野生数据集。(1) 一个商业反恶意软件供应商提供了29,573个可执行文件。这些在 "野外 "观察到的样本是从一个原始池中随机选择的，该池在2017-05-15至2017-09-19期间由反恶意软件供应商在美国的沙盒进行分析。随着良性/恶意标签和执行过程中观察到的恶意行为，供应商确定了哪个可执行文件被打包或未打包。（2）安德森等人引入了一个标记的基准数据集，称为EMBER，用于训练机器学习模型来静态检测Windows恶意软件。这个数据集包括800,000个被标记的Windows可执行文件。然而，没有提供关于包装的信息。我们从该数据集中随机选择了56,411个x86可执行文件，并将每个样本提交给商业反恶意软件供应商的沙盒，以确定该样本是否被打包。这也为我们提供了一个确认可执行文件是恶意软件还是良性软件的方式，因为沙盒会检测到恶意行为。请注意，这两个来源的样本是在2017年的某个时候 "在野外 "观察到的，这让目前的反恶意软件引擎有足够的时间纳入检测手段。由于这两个来源的样本可能有不正确的标签，我们进行了仔细和广泛的后处理步骤，我们在以下段落中描述。

#### Malicious vs. benign

> We used three different sources to detect whether an executable is malicious or benign. (1) VirusTotal: We obtained reports for our entire dataset by querying VirusTotal. All 85,984 executables in our dataset have been available on VirusTotal for more than one year. From all engines used by VirusTotal, we considered only seven tools that are well- known as strong products in the anti-malware industry and labeled each executable based on the majority vote. (2) The anti-malware vendor: Since we sent samples extracted from the EMBER dataset to the vendor’s sandbox, we have the benign/malicious label for all samples. (3) EMBER dataset: All samples that we selected from the EMBER dataset are labeled by Endgame.

我们使用三个不同的来源来检测一个可执行文件是恶意的还是良性的。(1) VirusTotal：我们通过查询VirusTotal获得整个数据集的报告。我们数据集中的所有85,984个可执行文件在VirusTotal上都有超过一年的时间。在VirusTotal使用的所有引擎中，我们只考虑了七个工具，它们在反恶意软件行业中是众所周知的强大产品，并根据多数人的投票对每个可执行文件进行了标注。(2) 反恶意软件供应商。由于我们将从EMBER数据集中提取的样本发送到供应商的沙盒中，我们对所有的样本都有良性/恶性标签。(3) EMBER数据集。我们从EMBER数据集中选择的所有样本都由Endgame标记。

> We discarded 4,113 samples for which there was a dis- agreement about their benign/malicious nature between the three sources. As Table I shows, at the end of this step, we have 37,269 benign and 44,602 malicious samples left (a total of 81,871 executables).

我们放弃了4,113个样本，因为这三个来源对它们的良性/恶意性质不一致。如`表一`所示，在这一步结束时，我们还剩下37,269个良性样本和44,602个恶意样本（总共有81,871个可执行文件）。

![image-20210424194938919](/Users/foo/Desktop/tmpimg/image-20210424194938919.png)

#### Packed vs. unpacked

> Due to the limitations discussed in Section III-A, we leveraged a hybrid approach to determine if an executable is packed. In particular, for each sample, we took the following steps: (1) The anti-malware vendor: We submitted the sample to the vendor’s sandbox, and given the downloaded report, we detected whether unpacking behavior had occurred or not. The anti-malware tool detects the presence of packed code by running the executable in a custom sandbox that interrupts the execution every time there is a write to a memory location followed by a jump to that address. At that point in time, a snapshot of the loaded instructions is compared to the original binary, and if they differ, the executable is marked as packed. (2) Deep Packer Inspector (*dpi*): We used *dpi* to further analyze each sample. This framework measures the runtime complexity of packers. Adding an extra dynamic engine helps us to identify packed executables that are not detected as packed by the first dynamic engine. For ex- ample, the host configuration might make the sample terminate before the unpacking process starts. In addition, this framework gives us insights about the runtime complexity of packers in our dataset. As *dpi* is not operating on .NET executables, we removed all 13,489 .NET executables, 10,681 benign and 2,808 malicious, from our dataset, resulting in 68,382 executables, 26,588 benign and 41,794 malicious. (3) Signatures and heuristics: We used *Manalyze*, *Exeinfo PE*, *yara* rules, *PEiD*, and *F-Prot* (from VirusTotal) to identify packers that leave noticeable artifacts in packed executables.

由于III-A节中讨论的局限性，我们利用一种混合方法来确定一个可执行文件是否被打包。特别是，对于每个样本，我们采取了以下步骤。(1) 反恶意软件供应商。我们将样本提交给供应商的沙盒，鉴于下载的报告，我们检测是否发生了解包行为。反恶意软件工具通过在一个自定义的沙盒中运行可执行文件来检测打包代码的存在，该沙盒在每次有写到一个内存位置并跳转到该地址时就会中断执行。在该时间点上，加载指令的快照与原始二进制文件进行比较，如果它们不同，可执行文件被标记为打包的。(2) Deep Packer Inspector (dpi)。我们使用dpi来进一步分析每个样本。这个框架衡量打包器的运行时复杂性。添加一个额外的动态引擎有助于我们识别未被第一个动态引擎检测为打包的可执行文件。例如，主机配置可能使样本在解包过程开始前就终止了。此外，这个框架让我们了解到数据集中打包程序的运行时复杂性。由于dpi不对.NET可执行文件进行操作，我们从数据集中删除了所有13,489个.NET可执行文件，其中10,681个是良性的，2,808个是恶意的，结果是68,382个可执行文件，26,588个是良性的，41,794个是恶意的。(3) 签名和启发式方法。我们使用Manalyze、Exeinfo PE、yara规则、PEiD和F-Prot（来自VirusTotal）来识别那些在打包的可执行文件中留下明显人工痕迹的打包器。

> In particular, we labeled an executable as packed in our dataset if one among the vendor’s sandbox, *dpi*, and signature- based tools detects the executable as packed. In total, we labeled 46,328 samples as packed divided into 12,647 benign and 33,681 malicious samples. We further used heuristics pro- posed by *Manalyze* for packing detection to determine samples that might be packed. *Manalyze* labeled 24,911 samples as “possibly packed,” of which 6,898 samples are not detected as packed by other tools. We argue that this discrepancy might be due to limitations with packing detection, which we discuss in Section III-A. Nevertheless, we discarded all these samples as we were not completely sure if they are packed or not.

特别地，在我们的数据集中，如果供应商的沙盒、dpi和基于签名的工具中的一个检测到可执行文件是打包的，我们就将其标记为打包。总的来说，我们将46328个样本标记为打包，分为12647个良性样本和33681个恶意样本。我们进一步使用Manalyze为打包检测提供的启发式方法来确定可能被打包的样本。Manalyze将24,911个样本标记为 "可能被打包"，其中6,898个样本没有被其他工具检测为被打包的。我们认为，这种差异可能是由于包装检测的局限性造成的，我们在第III-A节中讨论过。尽管如此，我们还是放弃了所有这些样本，因为我们不能完全确定它们是否是被打包的。

> Table X in the Appendix shows statistics about packed exe- cutables that are detected by each approach. Of 17,043 benign executables, 12,647 executables are packed, and 4,396 executa- bles are unpacked, and of 40,031 malicious executables, 33,681 executables are packed, and 5,752 executables are unpacked. While unpacked malware is shown to be rare, we did not detect packing for 5,752 (13.61%) malicious samples. Since this percentage could be considered somewhat higher than expected, we attempted to verify our packer analysis by randomly selecting 20 samples, and manually looking for the presence or absence of unpacking routines. We observed the unpacking routine code for 18 samples, but our packer detection scheme did not detect them due to the anti-detection techniques that these samples use. Since we do not need any *unpacked malicious* executables for our experiments, we discarded all 5,752 malicious samples that our system labeled as unpacked. To confirm that all 4,396 benign samples that we identified as unpacked are not packed, we manually looked into 100 unpacked benign executables and did not find any sign of packing. Simple statistics guarantee that more than 97.11% (95.59%) of these samples are labeled correctly with the confidence of 95% (99%).

附录中的`表X`显示了每种方法检测到的打包可执行文件的统计数据。在17,043个良性可执行文件中，12,647个可执行文件被打包，4,396个可执行文件未被打包；在40,031个恶意可执行文件中，33,681个可执行文件被打包，5,752个可执行文件未被打包。虽然未打包的恶意软件被证明是罕见的，但有5752个（13.61%）恶意样本没有检测到被打包。由于这个百分比可以被认为比预期的要高一些，我们试图通过随机选择20个样本来验证我们的打包器分析，并手动寻找是否存在未打包的程序。我们观察到18个样本的未打包例程代码，但由于这些样本使用的反检测技术，我们的打包器检测方案没有检测到它们。由于我们在实验中不需要任何未打包的恶意可执行文件，我们丢弃了所有被我们的系统标记为未打包的5752个恶意样本。为了确认所有被我们识别为未打包的4396个良性样本没有被打包，我们手动查看了100个未打包的良性可执行文件，没有发现任何打包的迹象。简单的统计学保证了这些样本中超过97.11%（95.59%）的样本被正确标记，置信度为95%（99%）。

> We further noticed that our dataset was skewed in terms of DLL files, containing 4,005 benign DLLs but only 598 malicious ones. We removed all these samples from our dataset. In the end, the *wild dataset* consists of 50,724 executables divided into 4,396 unpacked benign, 12,647 packed benign, and 33,681 packed malicious executables.

我们进一步注意到，我们的数据集在DLL文件方面是倾斜的，包含4,005个良性DLL，但只有598个恶性的DLL。我们从我们的数据集中删除了所有这些样本。最后，野生数据集由50,724个可执行文件组成，分为4,396个未打包的良性文件，12,647个打包的良性文件，以及33,681个打包的恶意可执行文件。

![image-20210424200759749](/Users/foo/Desktop/tmpimg/image-20210424200759749.png)

#### Packer complexity

> As Table X in the Appendix shows, *dpi* detects the unpacking behavior for 34,044 executables in the *wild dataset*. Table XI presents the packer complexity classes, as defined by Ugarte et al. , for these executables.

如附录中的`表X`所示，dpi检测了野生数据集中34,044个可执行文件的解包行为。`表XI`显示了Ugarte等人为这些可执行文件定义的打包器复杂性类别。

#### Packers in the wild

> Using *PEiD*, *F-Prot*, *Manalyze*, *Exeinfo PE*, and *yara* rules, we matched signatures of packers for 9,448 executables, 1,866 benign and 7,582 malicious. We found the artifacts of 48 packers in the *wild dataset*. As Table XII in the Appendix shows, some packers like dxpack, MPRESS, and PECompact have been used mostly in malicious samples.

使用PEiD、F-Prot、Manalyze、Exeinfo PE和yara规则，我们为9448个可执行文件匹配了打包器的签名，其中1866个是良性的，7582个是恶意的。我们在野外数据集中发现了48个打包器的工件。如附录中的`表XII`所示，一些打包器如dxpack、MPRESS和PECompact大多被用于恶意样本中。

![image-20210424201136975](/Users/foo/Desktop/tmpimg/image-20210424201136975.png)

### *B. Lab Dataset*

> Some of our experiments require us to know with certainty which packer is used to pack a program. Therefore, we obtained nine packers that are either commercially available or freeware (namely Obsidium, PELock, Themida, PECompact, Petite, UPX, kkrunchy, MPRESS, and tElock) and packed all 50,724 executables in our *wild dataset* to create the *lab dataset*. None of the packers were able to pack all samples. For example, Petite failed on most executables with a GUI, while Obsidium in some cases produced empty executables. We looked at logs generated by these packers and removed those executables that were not properly packed. We also verified that all packed executables have valid entry points. Finally, we developed our own simple packer, called *AES-Encrypter*, which, given the executable P, encrypts P using AES with a random key (which is included in the final binary), and injects the encrypted binary as the overlay of the packed binary P’. When P’ is executed, it first decrypts the overlay and then executes the decrypted (original) binary. Table II lists the number of samples we packed successfully with each packer. In total, we generated 341,444 packed executables. To ascertain if packing does, in fact, preserve the original behavior, we compared the behavior of these samples with the original samples. Our results confirm that 94.56% of samples exhibit the original behavior. We explain in Appendix C how we conducted this comparison.

我们的一些实验要求我们确切地知道哪个打包器是用来打包程序的。因此，我们获得了九种市售或免费的打包器（即Obsidium, PELock, Themida, PECompact, Petite, UPX, kkrunchy, MPRESS, and tElock），并对野生数据集中的所有50,724个可执行文件进行打包，以创建实验室数据集。没有一个打包器能够打包所有的样本。例如，Petite在大多数有GUI的可执行文件上失败了，而Obsidium在某些情况下产生了空的可执行文件。我们查看了这些打包器产生的日志，并删除了那些没有被正确打包的可执行文件。我们还验证了所有打包的可执行文件都有有效的入口点。最后，我们开发了自己的简单打包器，称为AES-加密器，它对于给定可执行文件P，用随机密钥（包括在最终的二进制文件中）用AES对P进行加密，并将加密的二进制文件作为打包后的二进制文件P'的覆盖层注入。当P'被执行时，它首先解密覆盖层，然后执行解密的（原始）二进制。`表II`列出了我们用每个打包器成功打包的样本数量。总的来说，我们产生了341,444个打包的可执行文件。为了确定打包是否确实保留了原始行为，我们将这些样本的行为与原始样本进行了比较。我们的结果证实，94.56%的样本表现出原始行为。我们在附录C中解释了我们如何进行这种比较。

![image-20210424202016327](/Users/foo/Desktop/tmpimg/image-20210424202016327.png)

### *C. Features*

> Following a detailed analysis of the literature (see Sec- tion B), we extracted nine families of static analysis features that were shown to be useful in related work. We used *pefile* to extract features from three different sources: the PE structure, the program’s assembly, and the raw bytes of the binary. As Table III shows, we extracted a total of 56,543 individual features from the samples in our dataset.

经过对文献的详细分析（见B节），我们提取了9个系列的静态分析特征，这些特征在相关工作中被证明是有用的。我们使用pefile从三个不同的来源提取特征：PE结构、程序的汇编和二进制文件的原始字节。如`表III`所示，我们从数据集中的样本中共提取了56,543个单独的特征。

#### (1) PE headers

> Features related to PE headers have been widely used in related work. In our case, we use all fields in the PE headers that exhibit some variability across differ- ent executables (some header fields never change). We extracted 12 individual features from the Optional and COFF headers, which are described in Table XX in the Appendix. Moreover, from the characteristics field in the COFF header, we extracted 16 binary features, each representing whether the corresponding flag is set for the executable or not. Thus, we extracted 12 integer and 16 binary features from the PE headers, resulting in a total of 28 features.

与PE头文件有关的特征已被广泛用于相关工作中。在我们的案例中，我们使用了PE头文件中的所有字段，这些字段在不同的可执行文件中表现出一定的可变性（有些头文件字段从未改变）。我们从Optional和COFF头文件中提取了12个单独的特征，这些特征在附录中的`表XX`中描述。此外，从COFF头中的特征字段中，我们提取了16个二进制特征，每个特征代表可执行文件中是否设置了相应的标志。因此，我们从PE头文件中提取了12个整数和16个二进制特征，总共有28个特征。

![image-20210424202321988](/Users/foo/Desktop/tmpimg/image-20210424202321988.png)

#### (2) PE sections

> Every executable has different sections, such as the .data and .text sections. For each section, we extracted 8 individual features as described in Table XXI in the Appendix. Moreover, from the characteristics field in the section header, we created up to 32 binary features for each bit (flag). For example, the feature corresponding to the 30th bit is true when the section is executable. We ignored the bits (flags) that do not vary in our dataset. For each section of the PE file, we computed 32 (at most) binary, 7 integer, and one string feature, named pesection sectionId field. The maximum number of sections that an executable has in our dataset is 19. For each executable, we built a vector of 516 different features obtained from its sections followed by the default values for sections that the sample does not include. Based on the related work, we augmented this set of features with the following processing steps: (1) We extracted the above- mentioned features for the section where the executable’s entry point resides and added them to the dataset separately; (2) We calculated the mean, minimum, and maximum entropy of the sections for each executable. We did the same for both the size and the virtual size attributes. As a result, we extracted a total of 570 features from the PE sections.

每个可执行文件都有不同的部分，如.data和.text部分。对于每个部分，我们提取了8个单独的特征，如附录中`表XXI`所描述。此外，从节头的特征字段中，我们为每个位（标志）创建了多达32个二进制特征。例如，对应于第30位的特征在该节可执行时为真。我们忽略了那些在我们的数据集中没有变化的位（标志）。对于PE文件的每个部分，我们计算了32个（最多）二进制、7个整数和一个字符串特征，命名为pesection sectionId字段。在我们的数据集中，一个可执行文件的最大节数是19。对于每个可执行文件，我们建立了一个由516个不同特征组成的向量，这些特征来自于它的部分，然后是样本中不包括的部分的默认值。基于相关的工作，我们用以下的处理步骤增加了这组特征。(1) 我们为可执行文件的入口点所在的部分提取了上述特征，并将它们分别添加到数据集中；(2) 我们计算了每个可执行文件的部分的平均、最小和最大熵。我们对大小和虚拟大小属性都做了同样的处理。结果，我们从PE部分共提取了570个特征。

![image-20210424202908176](/Users/foo/Desktop/tmpimg/image-20210424202908176.png)

#### (3) DLL imports

> Most executables are linked to dynamically-linked libraries (DLLs). For each library, we use a binary feature that is true when an executable uses that library. In total, we have 4,305 binary features in this set.

大多数可执行文件都被链接到动态链接库（DLLs）。对于每个库，我们使用一个二进制特征，当一个可执行文件使用该库时，该特征为真。在这组数据中，我们总共有4,305个二进制特征。

#### (4) API imports

> Every executable has an Import Directory Table that includes the APIs that the executable imports from external DLLs. We introduce a binary feature for each API function that is true if the executable imports that function. In total, we have 19,168 binary features in this set.

每个可执行文件都有一个导入目录表，其中包括可执行文件从外部DLLs导入的API。我们为每个API函数引入了一个二进制特征，如果可执行文件导入了该函数，则为真。在这个集合中，我们总共有19168个二进制特征。

#### (5) Rich Header

> The Rich Header field in the PE file includes information regarding the identity or type of the object files and the compiler used to build the executable. Webster et al. have shown that the Rich Header is useful for detecting different versions of malware, as malware authors often do not deliberately strip this header. In particular, they observed that “most packers, while sometimes introducing anomalies, did not often strip the Rich Header from samples.” Based on our observation, as Table II shows, while Obsidium, kkrunchy, MPRESS, and PELock stripped the Rich Header for 70–80% of binaries in the *wild dataset*, other packers always kept this header, except for *AES-Encrypter*, which always produces the same header. We followed the procedure by Webster et al. to encode this header into 66 integer features.

PE文件中的Rich Header字段包括有关对象文件的身份或类型以及用于构建可执行文件的编译器的信息。韦伯斯特等人表明，丰富的头信息对检测不同版本的恶意软件很有用，因为恶意软件作者通常不会故意剥离这个头信息。特别是，他们观察到，"大多数打包者，虽然有时会引入异常情况，但并不经常从样本中剥离富头"。根据我们的观察，如`表II`所示，虽然Obsidium, kkrunchy, MPRESS和PELock在野外数据集中剥离了70-80%的二进制文件的Rich Header，其他打包器总是保留这个头，除了AES-加密器，它总是产生相同的头。我们遵循Webster等人的程序，将这个头编码为66个整数特征。

#### (6) Byte n-grams

> Given that an executable file is a sequence of bytes, we extracted byte n-grams by considering every n consecutive bytes as an individual feature. Given the practical impossibility of storing the representation of n-grams for n ≥ 4 in main memory, a feature selection process is needed. Raff et al. observed that 6-grams perform best over their dataset. We used the same strategy to select the most important 6-gram features, where each feature represents if the executable contains the corresponding 6-gram. We first randomly selected a set of 1,000 samples and computed the number of files containing each individual 6-gram. We observed 1,060,957,223 unique 6-grams in these samples. As Figure 10a in the Appendix shows, and as Raff et al. observed, byte 6-grams follow a power-law type distribution, with 99.99% 6-grams occurring ten or fewer times. We reduced our set of candidate 6-grams by selecting 6-grams that occurred in more than 1% of the samples in the set, which results in 204,502 individual 6-gram features. Then, we selected the top 13,000 n-gram features based on the Information Gain (IG) measure, since our dataset roughly converges at this value, as depicted in Figure 10b.

鉴于可执行文件是一个字节序列，我们通过考虑每一个连续的n个字节作为一个单独的特征来提取字节n-grams。鉴于在主内存中不可能存储n≥4的n-grams的表示，需要一个特征选择过程。Raff等人观察到，6-grams在他们的数据集中表现最好。我们使用同样的策略来选择最重要的6-gram特征，其中每个特征代表可执行文件是否包含相应的6-gram。我们首先随机选择了一组1000个样本，并计算了包含每个单独的6-gram的文件数量。我们在这些样本中观察到1,060,957,223个独特的6-grams。正如附录中的`图10a`所示，以及Raff等人的观察，字节6-grams遵循幂律型分布，99.99%的6-grams出现了10次或更少。我们减少了候选6-grams的集合，选择了在集合中超过1%的样本中出现的6-grams，这就产生了204,502个单独的6-gram特征。然后，我们根据信息增益（IG）指标选择了前13,000个n-gram特征，因为我们的数据集大致收敛于这个值，如`图10b`所示。

![image-20210424203641722](/Users/foo/Desktop/tmpimg/image-20210424203641722.png)

#### (7) Opcode n-grams

> We used the Capstone disassembler to tokenize executables into sequences of opcodes and then built the opcode n-grams. While a small value may fail to detect complex malicious blocks of code, long sequences of opcodes can easily be avoided with simple obfuscation techniques. Moreover, large values of n introduce a high performance overhead. For these reasons, similarly to most related work, we use sequences up to a length of four. We represent opcode n-grams by computing the TF-IDF value for each sequence. While we could extract the assembly for all samples in the *wild dataset*, out of the 341,444 samples in the *lab dataset*, we could not disassemble 2,200 samples (see Table II). For these programs, we put -1 as the value of opcode n-grams features. In total, we extracted 5,373,170 unique opcode n-grams, from which, only 51,942 n-grams occurred in more than 0.1% of executables in the *lab dataset* (Figure 10c). We only consider these opcode n-grams (reduction of 98.47%). Figure 10d presents the Information Gain (IG) measure of these opcode n-grams. We selected the top 2,500 opcode n- grams (based on IG value) with their TF-IDF weights as feature values, resulting into 2,500 float features.

我们使用Capstone反汇编程序将可执行文件标记为操作码序列，然后建立操作码n-grams。虽然小的数值可能无法检测到复杂的恶意代码块，但长的操作码序列可以通过简单的混淆技术轻松避免。此外，大的n值会带来很高的性能开销。由于这些原因，与大多数相关工作类似，我们使用长度不超过4的序列。我们通过计算每个序列的TF-IDF值来表示操作码n-grams。虽然我们可以提取野生数据集中的所有样本的组装，但在实验室数据集中的341,444个样本中，我们有2200个样本不能反汇编（见`表II`）。对于这些程序，我们把-1作为opcode n-grams特征的值。我们总共提取了5,373,170个独特的操作码n-grams，其中，只有51,942个n-grams出现在实验室数据集中超过0.1%的可执行文件中（`图10c`）。我们只考虑这些操作码n-grams（减少98.47%）。`图10d`显示了这些操作码n-grams的信息增益（IG）指标。我们选择了前2500个操作码n-grams（基于IG值），用它们的TF-IDF权重作为特征值，从而得到2500个浮动特征。

#### (8) Strings

> The (printable) strings contained in an executable may give valuable insights into the executable, such as file names, system resource information, malware signatures, etc. We leveraged the GNU *strings* program to extract the printable character sequences that are at least 4 characters long. We rep- resent each printable string with a binary feature indicating if the executable contains the string. We observed 1,856,455,113 unique strings, from which more than 99.99% were seen in less than 0.4% of samples. After removing these rare strings, we obtained 16,900 binary features.

可执行文件中包含的（可打印的）字符串可能会对可执行文件提供有价值的参考，如文件名、系统资源信息、恶意软件的签名等。我们利用GNU字符串程序来提取至少有4个字符的可打印字符序列。我们用一个二进制特征来代表每个可打印的字符串，表明该可执行文件是否包含该字符串。我们观察到1,856,455,113个独特的字符串，其中99.99%以上的字符串在不到0.4%的样本中出现过。在去除这些罕见的字符串后，我们得到了16900个二进制特征。

#### (9) File generic

> We also computed the size of each sample (in bytes), and the entropy of the whole file. We further reference to this small family of features as “generic.”

我们还计算了每个样本的大小（以字节为单位），以及整个文件的熵值。我们进一步将这个小系列的特征称为 "通用"。

## V. EXPERIMENTS AND RESULTS

> In this work, we aim to answer the following question: does static analysis on packed binaries provide *rich enough* features to a malware classifier? We analyze multiple facets of this question by performing a number of experiments. As explained in the introduction, even though we used several machine learning approaches (i.e., SVM, neural networks and decision tress), we only discuss the results of the random forest approach as (1) we observed similar findings for these approaches, with random forest being the best classifier in most experiments, and (2) random forest allows for better interpretation of the results compared to neural networks. Following a linear search over different configurations of random forest, we found a suitable trade-off between learning time and test accuracy. Table XIX in the Appendix shows the parameters of the model.





























# 大摘要

## 标题

**When Malware is Packin’ Heat;Limits of Machine Learning Classifiers Based on Static Analysis Features**

恶意软件打包正热：基于静态分析的机器学习分类器的局限性

## 摘要

## 背景

### 要解决的问题

### 该问题的意义

### 主要贡献

## 主要工作

## 实验过程

## 结论

## 缺陷

## 启发